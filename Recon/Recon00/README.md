# Recon 00

## This exercise covers the robots.txt file



### Objective

### For this challenge, your goal is to retrieve the robots.txt from the main website for hackycorp.com. 

[The robots.txt file](https://en.wikipedia.org/wiki/Robots_exclusion_standard)


### The robots.txt file is used to tell web spiders how to crawl a website. To avoid having confidential information indexed and searchable, webmasters often use this file to tell spiders to avoid specific pages. This is done using the keyword Disallow. You can find more about the robots.txt file by reading Robots exclusion standard


## Solution:
***
    ┌──(hombresito㉿dope)-[~]
    └─$ curl http://hackycorp.com/robots.txt
        User-agent: *
        Disallow: /

        # You solved recon_00
        # The key for this challenge is
        # af9c328a-02b4-439d-91c6-f46ab4a0835b 
***